{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZXhd8FdUt2C"
      },
      "source": [
        "# Task 3: Graph Generation on ZINC Dataset with DDPM\n",
        "\n",
        "\n",
        "This notebook is adapted from the National University of Singapore CS5284 Graph Machine Learning course, the original tutorial code can be found at [here](https://github.com/xbresson/CS5284_2024/blob/main/codes/11_Graph_Generation/code06_solution.ipynb).\n",
        "\n",
        "> Some sections are adapted from the generation of GPT-4o and o3-mini models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvca_z_VUt2J",
        "outputId": "5be8c108-7381-47d2-d3ae-ac848e252b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/gt_v2\n",
            "Requirement already satisfied: dgl==1.0.0 in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.0.0) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.0.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.0.0) (2024.12.14)\n",
            "Requirement already satisfied: rdkit==2023.09.6 in /usr/local/lib/python3.11/dist-packages (2023.9.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit==2023.09.6) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit==2023.09.6) (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "# For Google Colaboratory\n",
        "import sys, os\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive/\")\n",
        "    path = \"/content/drive/MyDrive/yanming_dissertation/gtv2/code/\"\n",
        "    os.chdir(path)\n",
        "    !pwd\n",
        "    !pip install dgl==1.0.0\n",
        "    !pip install rdkit==2023.09.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i2lb5gT0Ut2L"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import networkx as nx\n",
        "import sys; sys.path.insert(0, \"lib/\")\n",
        "from lib.molecules import Dictionary, MoleculeDataset, MoleculeDGL, Molecule, compute_ncut, from_pymol_to_smile\n",
        "import os, datetime\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.Chem import rdmolops\n",
        "from rdkit import RDLogger\n",
        "RDLogger.DisableLog(\"rdApp.*\")\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5TrPWZCUt2M",
        "outputId": "aeba905e-cb0b-4bf8-d807-ecd9a50d2ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu124\n",
            "Tesla T4\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# PyTorch version and GPU\n",
        "print(torch.__version__)\n",
        "if torch.cuda.is_available():\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "  device= torch.device(\"cuda\")\n",
        "else:\n",
        "  device= torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjqOuIUmUt2M"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "TMSsmWEfUt2N",
        "outputId": "be3c751f-0956-42f6-a699-143b5245902d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "dataset/ZINC/\n",
            "Time: 1.7459 sec\n",
            "num train data : 2000\n",
            "atom_dict.idx2word : ['C', 'O', 'N', 'F', 'C H1', 'S', 'Cl', 'O -', 'N H1 +', 'Br', 'N H3 +', 'N H2 +', 'N +', 'N -', 'I', 'S -', 'P', 'N H1 -']\n",
            "atom_dict.word2idx : {'C': 0, 'O': 1, 'N': 2, 'F': 3, 'C H1': 4, 'S': 5, 'Cl': 6, 'O -': 7, 'N H1 +': 8, 'Br': 9, 'N H3 +': 10, 'N H2 +': 11, 'N +': 12, 'N -': 13, 'I': 14, 'S -': 15, 'P': 16, 'N H1 -': 17}\n",
            "bond_dict.idx2word : ['NONE', 'SINGLE', 'DOUBLE', 'TRIPLE']\n",
            "bond_dict.word2idx : {'NONE': 0, 'SINGLE': 1, 'DOUBLE': 2, 'TRIPLE': 3}\n",
            "18 4\n",
            "train[idx].atom_type : tensor([0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 2, 0, 5])\n",
            "train[idx].atom_type_pe : tensor([ 0,  1,  2,  3,  4,  5,  6,  0,  1,  7,  2,  8,  9, 10, 11, 12,  3, 13,\n",
            "        14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,  0,  4, 25,  0])\n",
            "train[idx].bond_type : tensor([[0, 1, 0,  ..., 0, 0, 0],\n",
            "        [1, 0, 1,  ..., 0, 0, 0],\n",
            "        [0, 1, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 2, 0],\n",
            "        [0, 0, 0,  ..., 2, 0, 1],\n",
            "        [0, 0, 0,  ..., 0, 1, 0]])\n",
            "train[idx].bag_of_atoms : tensor([26,  1,  5,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n",
            "train[idx].smile:  CCCCCCC1=NN2C(=N)C(=CC3=C(C)N(C4=CC=C(C)C=C4C)C(C)=C3)C(=O)N=C2S1\n",
            "train[idx].logP_SA tensor([3.4121])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7ce416977c30>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Loading data...\")\n",
        "start = time.time()\n",
        "\n",
        "data_folder_pytorch = \"dataset/ZINC/\"\n",
        "print(data_folder_pytorch)\n",
        "\n",
        "with open(data_folder_pytorch+\"atom_dict.pkl\",\"rb\") as f:\n",
        "    atom_dict=pickle.load(f)\n",
        "with open(data_folder_pytorch+\"bond_dict.pkl\",\"rb\") as f:\n",
        "    bond_dict=pickle.load(f)\n",
        "with open(data_folder_pytorch+\"train.pkl\",\"rb\") as f:\n",
        "    train=pickle.load(f)\n",
        "with open(data_folder_pytorch+\"val.pkl\",\"rb\") as f:\n",
        "    val=pickle.load(f)\n",
        "with open(data_folder_pytorch+\"test.pkl\",\"rb\") as f:\n",
        "    test=pickle.load(f)\n",
        "\n",
        "print(f\"Time: {time.time() - start:.4f} sec\")\n",
        "\n",
        "print(\"num train data :\", len(train))\n",
        "print(\"atom_dict.idx2word :\", atom_dict.idx2word)\n",
        "print(\"atom_dict.word2idx :\", atom_dict.word2idx)\n",
        "print(\"bond_dict.idx2word :\", bond_dict.idx2word)\n",
        "print(\"bond_dict.word2idx :\", bond_dict.word2idx)\n",
        "\n",
        "num_atom_type = len(atom_dict.idx2word)\n",
        "num_bond_type = len(bond_dict.idx2word)\n",
        "print(num_atom_type, num_bond_type)\n",
        "\n",
        "idx = 0\n",
        "print(\"train[idx].atom_type :\", train[idx].atom_type)\n",
        "print(\"train[idx].atom_type_pe :\", train[idx].atom_type_pe)\n",
        "print(\"train[idx].bond_type :\", train[idx].bond_type)\n",
        "print(\"train[idx].bag_of_atoms :\", train[idx].bag_of_atoms)\n",
        "print(\"train[idx].smile: \", train[idx].smile)\n",
        "print(\"train[idx].logP_SA\", train[idx].logP_SA)\n",
        "mol = Chem.MolFromSmiles(train[idx].smile)\n",
        "mol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xahWlDsLUt2N"
      },
      "source": [
        "## Dataset Statistics\n",
        "\n",
        "### Grouping Molecules by Number of Atoms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP8msgBsUt2O",
        "outputId": "97a84160-8f56-4197-bbec-bc241b93d959"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max num atoms =  37\n",
            "\n",
            "Train\n",
            "number of molecule of size 7: \t 1\n",
            "number of molecule of size 9: \t 1\n",
            "number of molecule of size 10: \t 2\n",
            "number of molecule of size 11: \t 4\n",
            "number of molecule of size 12: \t 5\n",
            "number of molecule of size 13: \t 17\n",
            "number of molecule of size 14: \t 24\n",
            "number of molecule of size 15: \t 30\n",
            "number of molecule of size 16: \t 51\n",
            "number of molecule of size 17: \t 61\n",
            "number of molecule of size 18: \t 89\n",
            "number of molecule of size 19: \t 107\n",
            "number of molecule of size 20: \t 145\n",
            "number of molecule of size 21: \t 152\n",
            "number of molecule of size 22: \t 159\n",
            "number of molecule of size 23: \t 175\n",
            "number of molecule of size 24: \t 183\n",
            "number of molecule of size 25: \t 169\n",
            "number of molecule of size 26: \t 174\n",
            "number of molecule of size 27: \t 135\n",
            "number of molecule of size 28: \t 85\n",
            "number of molecule of size 29: \t 69\n",
            "number of molecule of size 30: \t 37\n",
            "number of molecule of size 31: \t 44\n",
            "number of molecule of size 32: \t 29\n",
            "number of molecule of size 33: \t 22\n",
            "number of molecule of size 34: \t 13\n",
            "number of molecule of size 35: \t 10\n",
            "number of molecule of size 36: \t 4\n",
            "number of molecule of size 37: \t 3\n",
            "Val\n",
            "number of molecule of size 11: \t 1\n",
            "number of molecule of size 12: \t 1\n",
            "number of molecule of size 13: \t 3\n",
            "number of molecule of size 14: \t 1\n",
            "number of molecule of size 15: \t 5\n",
            "number of molecule of size 16: \t 8\n",
            "number of molecule of size 17: \t 14\n",
            "number of molecule of size 18: \t 8\n",
            "number of molecule of size 19: \t 12\n",
            "number of molecule of size 20: \t 13\n",
            "number of molecule of size 21: \t 14\n",
            "number of molecule of size 22: \t 11\n",
            "number of molecule of size 23: \t 15\n",
            "number of molecule of size 24: \t 25\n",
            "number of molecule of size 25: \t 21\n",
            "number of molecule of size 26: \t 16\n",
            "number of molecule of size 27: \t 6\n",
            "number of molecule of size 28: \t 8\n",
            "number of molecule of size 29: \t 5\n",
            "number of molecule of size 30: \t 5\n",
            "number of molecule of size 31: \t 2\n",
            "number of molecule of size 32: \t 1\n",
            "number of molecule of size 33: \t 2\n",
            "number of molecule of size 34: \t 3\n",
            "Test\n",
            "number of molecule of size 12: \t 1\n",
            "number of molecule of size 13: \t 1\n",
            "number of molecule of size 14: \t 2\n",
            "number of molecule of size 15: \t 5\n",
            "number of molecule of size 16: \t 4\n",
            "number of molecule of size 17: \t 7\n",
            "number of molecule of size 18: \t 16\n",
            "number of molecule of size 19: \t 7\n",
            "number of molecule of size 20: \t 11\n",
            "number of molecule of size 21: \t 17\n",
            "number of molecule of size 22: \t 8\n",
            "number of molecule of size 23: \t 14\n",
            "number of molecule of size 24: \t 21\n",
            "number of molecule of size 25: \t 16\n",
            "number of molecule of size 26: \t 12\n",
            "number of molecule of size 27: \t 21\n",
            "number of molecule of size 28: \t 5\n",
            "number of molecule of size 29: \t 11\n",
            "number of molecule of size 30: \t 3\n",
            "number of molecule of size 31: \t 7\n",
            "number of molecule of size 32: \t 4\n",
            "number of molecule of size 33: \t 4\n",
            "number of molecule of size 34: \t 2\n",
            "number of molecule of size 36: \t 1\n"
          ]
        }
      ],
      "source": [
        "# Organize data into group of of molecules of fixed sized\n",
        "# Example: train[9] is a list containing all the molecules of size 9\n",
        "def group_molecules_per_size(dataset):\n",
        "    mydict = {}\n",
        "    for mol in dataset:\n",
        "        if len(mol) not in mydict:\n",
        "            mydict[len(mol)] = []\n",
        "        mydict[len(mol)].append(mol)\n",
        "    return mydict\n",
        "\n",
        "test_group  = group_molecules_per_size(test)\n",
        "val_group   = group_molecules_per_size(val)\n",
        "train_group = group_molecules_per_size(train)\n",
        "\n",
        "# The biggest molecule in the train set\n",
        "max_mol_sz= max(list( train_group.keys()))\n",
        "print(\"Max num atoms = \", max_mol_sz)\n",
        "\n",
        "# Print distribution w.r.t. molecule size\n",
        "def print_distribution(data):\n",
        "    for nb_atom in range(max_mol_sz+1):\n",
        "        try:\n",
        "            print(\"number of molecule of size {}: \\t {}\".format(nb_atom, len(data[nb_atom])))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "print()\n",
        "print(\"Train\"); print_distribution(train_group)\n",
        "print(\"Val\"); print_distribution(val_group)\n",
        "print(\"Test\"); print_distribution(test_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1-8R6gzUq-t"
      },
      "source": [
        "### Sampling Molecules from Train Set through Possibility Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYDfyD9mUq-u",
        "outputId": "3893f3ac-4460-4729-8e96-c72581bb7fc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sampler_size.num_mol : {33: 22, 18: 89, 26: 174, 16: 51, 32: 29, 22: 159, 34: 13, 27: 135, 23: 175, 20: 145, 25: 169, 28: 85, 24: 183, 19: 107, 29: 69, 14: 24, 36: 4, 21: 152, 31: 44, 17: 61, 30: 37, 11: 4, 12: 5, 13: 17, 35: 10, 15: 30, 37: 3, 7: 1, 10: 2, 9: 1}\n",
            "sz : 17\n"
          ]
        }
      ],
      "source": [
        "class sample_molecule_size:\n",
        "    def __init__(self, organized_dataset):\n",
        "        self.num_mol = {sz: len(list_of_mol) for sz, list_of_mol in organized_dataset.items()}\n",
        "        self.num_batches_remaining = {sz: self.num_mol[sz] for sz in self.num_mol}\n",
        "    def choose_molecule_size(self):\n",
        "        num_batches = self.num_batches_remaining\n",
        "        possible_sizes = np.array( list( num_batches.keys()) )\n",
        "        prob = np.array( list( num_batches.values() )   )\n",
        "        prob = prob / prob.sum()\n",
        "        sz = np.random.choice(  possible_sizes , p=prob )\n",
        "        return sz\n",
        "\n",
        "sampler_size = sample_molecule_size(train_group)\n",
        "print('sampler_size.num_mol :',sampler_size.num_mol)\n",
        "sz = sampler_size.choose_molecule_size()\n",
        "print('sz :',sz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ynx7hRWUt2O"
      },
      "source": [
        "## Generate Batches\n",
        "\n",
        "### Implement the molecule sampler class for batch sampling of molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mr3fGKBeUt2P"
      },
      "outputs": [],
      "source": [
        "class MoleculeSampler:\n",
        "    def __init__(self, organized_dataset, bs, shuffle=True):\n",
        "        self.bs = bs\n",
        "        self.num_mol =  {sz: len(list_of_mol) for sz, list_of_mol in organized_dataset.items()}\n",
        "        self.counter = {sz: 0   for sz in organized_dataset}\n",
        "        if shuffle:\n",
        "            self.order = {sz: np.random.permutation(num)  for sz , num in self.num_mol.items()}\n",
        "        else:\n",
        "            self.order = {sz: np.arange(num)  for sz , num in self.num_mol.items()}\n",
        "\n",
        "    def compute_num_batches_remaining(self):\n",
        "        return {sz:  math.ceil(((self.num_mol[sz] - self.counter[sz])/self.bs))  for sz in self.num_mol}\n",
        "\n",
        "    def choose_molecule_size(self):\n",
        "        num_batches = self.compute_num_batches_remaining()\n",
        "        possible_sizes = np.array(list(num_batches.keys()))\n",
        "        prob = np.array(list(num_batches.values()))\n",
        "        prob = prob / prob.sum()\n",
        "        sz   = np.random.choice(possible_sizes, p=prob)\n",
        "        return sz\n",
        "\n",
        "    def is_empty(self):\n",
        "        num_batches= self.compute_num_batches_remaining()\n",
        "        return sum(num_batches.values()) == 0\n",
        "\n",
        "    def draw_batch_of_molecules(self, sz):\n",
        "        if (self.num_mol[sz] - self.counter[sz]) / self.bs >= 1.0:\n",
        "            bs = self.bs\n",
        "        else:\n",
        "            bs = self.num_mol[sz] - (self.num_mol[sz] // self.bs) * self.bs\n",
        "        indices = self.order[sz][self.counter[sz]:self.counter[sz] + bs]\n",
        "        self.counter[sz] += bs\n",
        "        return indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPFhgO6UUt2P"
      },
      "source": [
        "### Extract one example mini-batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIs10DlGUt2P",
        "outputId": "adbeda5d-fa8e-4a9e-e152-8c61198f56ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sampler.num_mol : {33: 22, 18: 89, 26: 174, 16: 51, 32: 29, 22: 159, 34: 13, 27: 135, 23: 175, 20: 145, 25: 169, 28: 85, 24: 183, 19: 107, 29: 69, 14: 24, 36: 4, 21: 152, 31: 44, 17: 61, 30: 37, 11: 4, 12: 5, 13: 17, 35: 10, 15: 30, 37: 3, 7: 1, 10: 2, 9: 1}\n",
            "num_batches_remaining : {33: 1, 18: 2, 26: 4, 16: 2, 32: 1, 22: 4, 34: 1, 27: 3, 23: 4, 20: 3, 25: 4, 28: 2, 24: 4, 19: 3, 29: 2, 14: 1, 36: 1, 21: 4, 31: 1, 17: 2, 30: 1, 11: 1, 12: 1, 13: 1, 35: 1, 15: 1, 37: 1, 7: 1, 10: 1, 9: 1}\n",
            "sz : 21\n",
            "indices : 50 [ 62  42   5 138 124  79  11 118  24 143  45  64  14  58  57  17  85  98\n",
            "  35  15 110  32  53 123   2 151  96  93  28  22 150 125   4  94 116  99\n",
            "  27  52  78  55  97 141  49  29   7  13 135   3  48  77]\n",
            "minibatch_node : torch.Size([50, 21])\n",
            "minibatch_pe : torch.Size([50, 21])\n",
            "minibatch_edge : torch.Size([50, 21, 21])\n",
            "minibatch_boa : torch.Size([50, 18])\n"
          ]
        }
      ],
      "source": [
        "# extract one mini-batch\n",
        "bs = 50\n",
        "sampler = MoleculeSampler(train_group, bs)\n",
        "print('sampler.num_mol :', sampler.num_mol)\n",
        "\n",
        "num_batches_remaining = sampler.compute_num_batches_remaining()\n",
        "print('num_batches_remaining :', num_batches_remaining)\n",
        "sz = sampler.choose_molecule_size()\n",
        "print('sz :', sz)\n",
        "indices = sampler.draw_batch_of_molecules(sz)\n",
        "print('indices :', len(indices), indices)\n",
        "minibatch_node = torch.stack([train_group[sz][i].atom_type for i in indices])\n",
        "print('minibatch_node :', minibatch_node.size())\n",
        "minibatch_pe  = torch.stack([train_group[sz][i].atom_type_pe for i in indices])\n",
        "print('minibatch_pe :', minibatch_pe.size())\n",
        "minibatch_edge = torch.stack([ train_group[sz][i].bond_type for i in indices])\n",
        "print('minibatch_edge :', minibatch_edge.size())\n",
        "minibatch_boa = torch.stack([train_group[sz][i].bag_of_atoms for i in indices])\n",
        "print('minibatch_boa :', minibatch_boa.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZunx_C9Ut2Q"
      },
      "source": [
        "## DDPM Model\n",
        "\n",
        "### Global Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Iy7fOuGUt2Q",
        "outputId": "c72e2bbb-2b0e-4fd7-c5db-683e3416196b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_heads, d, num_layers, dPEt, drop, bs :  4 128 6 128 0.0 10\n",
            "beta_1, beta_T, num_t : 0.0001 0.02 150\n",
            "num_warmup : 400\n"
          ]
        }
      ],
      "source": [
        "# Global constants\n",
        "num_heads = 4 # number of heads in the transformer layer\n",
        "d = 32 * num_heads # number of hidden dimensions\n",
        "num_layers = 6 # number of transformer layers\n",
        "dPEt = d # number of dimensions for the time step of the diffusion model\n",
        "drop = 0.0 # dropout value\n",
        "bs = 10 # batch size\n",
        "\n",
        "print('num_heads, d, num_layers, dPEt, drop, bs : ', num_heads, d, num_layers, dPEt, drop, bs)\n",
        "\n",
        "beta_1 = 0.0001 # beta_1 for DM\n",
        "beta_T = 0.02 # beta_T for DM\n",
        "num_t = 150 # number of time steps of the DM\n",
        "alpha_t = 1.0 - torch.linspace(beta_1, beta_T, num_t).to(device) # for DM, size=[num_t]\n",
        "alpha_bar_t = torch.cumprod( alpha_t, dim=0) # for DM, size=[num_t]\n",
        "print('beta_1, beta_T, num_t :', beta_1, beta_T, num_t)\n",
        "\n",
        "# Warmup\n",
        "num_mol_size = 20\n",
        "num_warmup = 2 * max( num_mol_size, len(train) // bs ) # 4 epochs * max( num_mol_size=20, num_mol/batch_size)\n",
        "print('num_warmup :',num_warmup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlpmO2lTUt2S"
      },
      "source": [
        "### Instantiate and test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOUDjIg9Ut2S",
        "outputId": "9169db24-3f15-40c2-bf00-e5866c77e921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 2773526 (2.77 million)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sampler.num_mol : {33: 22, 18: 89, 26: 174, 16: 51, 32: 29, 22: 159, 34: 13, 27: 135, 23: 175, 20: 145, 25: 169, 28: 85, 24: 183, 19: 107, 29: 69, 14: 24, 36: 4, 21: 152, 31: 44, 17: 61, 30: 37, 11: 4, 12: 5, 13: 17, 35: 10, 15: 30, 37: 3, 7: 1, 10: 2, 9: 1}\n",
            "num_batches_remaining : {33: 3, 18: 9, 26: 18, 16: 6, 32: 3, 22: 16, 34: 2, 27: 14, 23: 18, 20: 15, 25: 17, 28: 9, 24: 19, 19: 11, 29: 7, 14: 3, 36: 1, 21: 16, 31: 5, 17: 7, 30: 4, 11: 1, 12: 1, 13: 2, 35: 1, 15: 3, 37: 1, 7: 1, 10: 1, 9: 1}\n",
            "sz : 21\n",
            "minibatch_node : torch.Size([10, 21])\n",
            "minibatch_edge : torch.Size([10, 21, 21])\n",
            "batch_sample_t torch.Size([10])\n",
            "batch_noise_x_t torch.Size([10, 21, 18]) batch_noise_e_t torch.Size([10, 21, 21, 4])\n",
            "x_t torch.Size([10, 21, 18]) e_t torch.Size([10, 21, 21, 4])\n",
            "noise_pred_x_t torch.Size([10, 21, 18]) noise_pred_e_t torch.Size([10, 21, 21, 4])\n",
            "batch_x_0 torch.Size([4, 9, 18]) batch_e_0 torch.Size([4, 9, 9, 4])\n"
          ]
        }
      ],
      "source": [
        "from models.gtv1 import UNet_vanilla\n",
        "from models.gtv2_weighted import UNet_weighted\n",
        "from models.gtv2_gated import UNet_gated\n",
        "from models.gtv2_mixed import UNet_mixed\n",
        "from models.gtv2_film import UNet_film\n",
        "from models.ddpm import DDPM\n",
        "\n",
        "def sym_tensor(x):\n",
        "    x = x.permute(0,3,1,2) # [bs, d, n, n]\n",
        "    triu = torch.triu(x,diagonal=1).transpose(3,2) # [bs, d, n, n]\n",
        "    mask = (triu.abs()>0).float()                  # [bs, d, n, n]\n",
        "    x =  x * (1 - mask ) + mask * triu             # [bs, d, n, n]\n",
        "    x = x.permute(0,2,3,1) # [bs, n, n, d]\n",
        "    return x               # [bs, n, n, d]\n",
        "\n",
        "# Instantiate the network\n",
        "gt = UNet_film(d, num_heads, num_layers, num_atom_type, num_bond_type, num_t, max_mol_sz, dPEt, device, drop)\n",
        "net = DDPM(num_t, beta_1, beta_T, gt, num_atom_type, num_bond_type, device).to(device)\n",
        "\n",
        "def display_num_param(net):\n",
        "    nb_param = 0\n",
        "    for param in net.parameters():\n",
        "        nb_param += param.numel()\n",
        "    print('Number of parameters: {} ({:.2f} million)'.format(nb_param, nb_param/1e6))\n",
        "    return nb_param/1e6\n",
        "_ = display_num_param(net)\n",
        "\n",
        "# Test the forward pass, backward pass and gradient update with a single batch\n",
        "init_lr = 0.001\n",
        "optimizer = torch.optim.AdamW(net.parameters(), lr=init_lr)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.95, patience=1, verbose=True)\n",
        "\n",
        "sampler = MoleculeSampler(train_group, bs)\n",
        "print('sampler.num_mol :',sampler.num_mol)\n",
        "num_batches_remaining = sampler.compute_num_batches_remaining()\n",
        "print('num_batches_remaining :',num_batches_remaining)\n",
        "sz = sampler.choose_molecule_size()\n",
        "print('sz :',sz)\n",
        "indices = sampler.draw_batch_of_molecules(sz)\n",
        "batch_x0 = minibatch_node = torch.stack( [ train_group[sz][i].atom_type for i in indices] ).long().to(device) # [bs, n]\n",
        "print('minibatch_node :',minibatch_node.size())\n",
        "batch_e0 = minibatch_edge = torch.stack( [ train_group[sz][i].bond_type for i in indices] ).long().to(device) # [bs, n, n]\n",
        "print('minibatch_edge :',minibatch_edge.size())\n",
        "batch_sample_t = torch.randint(0, num_t, (batch_x0.size(0),)).long().to(device) # random interger in {0,1,...,T-1} [bs]\n",
        "print('batch_sample_t',batch_sample_t.size())\n",
        "\n",
        "bs2, n = batch_x0.size()\n",
        "batch_noise_x_t = torch.randn(bs2,n,num_atom_type).to(device) # [bs, n, num_atom_type]\n",
        "batch_noise_e_t = torch.randn(bs2,n,n,num_bond_type).to(device) # [bs, n, n, num_bond_type]\n",
        "batch_noise_e_t = sym_tensor(batch_noise_e_t)\n",
        "\n",
        "print('batch_noise_x_t',batch_noise_x_t.size(),'batch_noise_e_t',batch_noise_e_t.size())\n",
        "x_t, e_t = net.forward_process(batch_x0, batch_e0, batch_sample_t, batch_noise_x_t, batch_noise_e_t) # [bs, n], [bs, n, n]\n",
        "print('x_t',x_t.size(), 'e_t',e_t.size())\n",
        "\n",
        "noise_pred_x_t, noise_pred_e_t = net.backward_process(x_t, e_t, batch_sample_t) # [bs, n], [bs, n, n]\n",
        "print('noise_pred_x_t',noise_pred_x_t.size(),'noise_pred_e_t',noise_pred_e_t.size())\n",
        "\n",
        "loss_DDPM = torch.nn.MSELoss()(noise_pred_x_t, batch_noise_x_t) + 1.0* torch.nn.MSELoss()(noise_pred_e_t, batch_noise_e_t)\n",
        "loss = loss_DDPM\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "torch.nn.utils.clip_grad_norm_(net.parameters(), 0.25) # grad_norm_clip=1.0\n",
        "optimizer.step()\n",
        "\n",
        "with torch.no_grad():\n",
        "    batch_x_0, batch_e_0 = net.generate_process_ddpm(4, 9)\n",
        "    print('batch_x_0',batch_x_0.size(), 'batch_e_0',batch_e_0.size())\n",
        "\n",
        "del gt, net\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVA6tjsjUt2T"
      },
      "source": [
        "## Train And Evaluate The Model\n",
        "\n",
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKhmIjB1Ut2T",
        "outputId": "e5d35177-8e2d-4c7a-b7a2-ba82bb274760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_heads, d, num_layers, dPEt, drop, bs :  4 128 6 128 0.0 10\n",
            "beta_1, beta_T, num_t : 0.0001 0.02 150\n",
            "num_warmup, nb_epochs : 400 50\n",
            "epoch= 0 \t time= 0.4937 min \t lr= 0.0001620 \t loss= 1.8259\n",
            "epoch= 1 \t time= 0.9516 min \t lr= 0.0003000 \t loss= 0.6268\n",
            "epoch= 2 \t time= 1.4222 min \t lr= 0.0003000 \t loss= 0.3511\n",
            "epoch= 3 \t time= 1.8774 min \t lr= 0.0003000 \t loss= 0.2944\n",
            "epoch= 4 \t time= 2.3393 min \t lr= 0.0003000 \t loss= 0.2391\n",
            "epoch= 5 \t time= 2.7957 min \t lr= 0.0003000 \t loss= 0.2061\n",
            "epoch= 6 \t time= 3.2542 min \t lr= 0.0003000 \t loss= 0.1701\n",
            "epoch= 7 \t time= 3.7164 min \t lr= 0.0003000 \t loss= 0.1708\n",
            "epoch= 8 \t time= 4.1747 min \t lr= 0.0003000 \t loss= 0.1464\n",
            "epoch= 9 \t time= 4.6340 min \t lr= 0.0003000 \t loss= 0.1347\n",
            "epoch= 10 \t time= 5.0913 min \t lr= 0.0003000 \t loss= 0.1331\n",
            "epoch= 11 \t time= 5.5543 min \t lr= 0.0003000 \t loss= 0.1192\n",
            "epoch= 12 \t time= 6.0114 min \t lr= 0.0003000 \t loss= 0.1163\n",
            "epoch= 13 \t time= 6.4709 min \t lr= 0.0003000 \t loss= 0.1148\n",
            "epoch= 14 \t time= 6.9319 min \t lr= 0.0003000 \t loss= 0.0981\n",
            "epoch= 15 \t time= 7.3877 min \t lr= 0.0003000 \t loss= 0.1029\n",
            "epoch= 16 \t time= 7.8451 min \t lr= 0.0003000 \t loss= 0.0921\n",
            "epoch= 17 \t time= 8.2989 min \t lr= 0.0003000 \t loss= 0.0889\n",
            "epoch= 18 \t time= 8.7516 min \t lr= 0.0003000 \t loss= 0.0870\n",
            "epoch= 19 \t time= 9.2066 min \t lr= 0.0003000 \t loss= 0.0922\n",
            "epoch= 20 \t time= 9.6654 min \t lr= 0.0002850 \t loss= 0.0908\n",
            "epoch= 21 \t time= 10.1222 min \t lr= 0.0002850 \t loss= 0.0814\n",
            "epoch= 22 \t time= 10.5795 min \t lr= 0.0002850 \t loss= 0.0823\n",
            "epoch= 23 \t time= 11.0599 min \t lr= 0.0002850 \t loss= 0.0777\n",
            "epoch= 24 \t time= 11.5154 min \t lr= 0.0002850 \t loss= 0.0834\n",
            "epoch= 25 \t time= 11.9700 min \t lr= 0.0002850 \t loss= 0.0719\n",
            "epoch= 26 \t time= 12.4278 min \t lr= 0.0002850 \t loss= 0.0767\n",
            "epoch= 27 \t time= 12.8845 min \t lr= 0.0002707 \t loss= 0.0721\n",
            "epoch= 28 \t time= 13.3404 min \t lr= 0.0002707 \t loss= 0.0736\n",
            "epoch= 29 \t time= 13.8001 min \t lr= 0.0002707 \t loss= 0.0712\n",
            "epoch= 30 \t time= 14.2567 min \t lr= 0.0002707 \t loss= 0.0724\n",
            "epoch= 31 \t time= 14.7146 min \t lr= 0.0002707 \t loss= 0.0672\n",
            "epoch= 32 \t time= 15.1755 min \t lr= 0.0002707 \t loss= 0.0673\n",
            "epoch= 33 \t time= 15.6376 min \t lr= 0.0002572 \t loss= 0.0678\n",
            "epoch= 34 \t time= 16.0945 min \t lr= 0.0002572 \t loss= 0.0665\n",
            "epoch= 35 \t time= 16.5511 min \t lr= 0.0002572 \t loss= 0.0635\n",
            "epoch= 36 \t time= 17.0056 min \t lr= 0.0002572 \t loss= 0.0634\n",
            "epoch= 37 \t time= 17.4593 min \t lr= 0.0002572 \t loss= 0.0606\n",
            "epoch= 38 \t time= 17.9162 min \t lr= 0.0002572 \t loss= 0.0609\n",
            "epoch= 39 \t time= 18.3710 min \t lr= 0.0002444 \t loss= 0.0614\n",
            "epoch= 40 \t time= 18.8245 min \t lr= 0.0002444 \t loss= 0.0610\n",
            "epoch= 41 \t time= 19.2799 min \t lr= 0.0002321 \t loss= 0.0643\n",
            "epoch= 42 \t time= 19.7327 min \t lr= 0.0002321 \t loss= 0.0570\n",
            "epoch= 43 \t time= 20.1864 min \t lr= 0.0002321 \t loss= 0.0569\n",
            "epoch= 44 \t time= 20.6423 min \t lr= 0.0002321 \t loss= 0.0600\n",
            "epoch= 45 \t time= 21.1016 min \t lr= 0.0002205 \t loss= 0.0585\n",
            "epoch= 46 \t time= 21.5584 min \t lr= 0.0002205 \t loss= 0.0546\n",
            "epoch= 47 \t time= 22.0243 min \t lr= 0.0002205 \t loss= 0.0543\n",
            "epoch= 48 \t time= 22.4818 min \t lr= 0.0002205 \t loss= 0.0529\n",
            "epoch= 49 \t time= 22.9364 min \t lr= 0.0002205 \t loss= 0.0558\n"
          ]
        }
      ],
      "source": [
        "# Random seed\n",
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "gt = UNet_film(d, num_heads, num_layers, num_atom_type, num_bond_type, num_t, max_mol_sz, dPEt, device, drop)\n",
        "net = DDPM(num_t, beta_1, beta_T, gt, num_atom_type, num_bond_type, device).to(device)\n",
        "\n",
        "# Optimizer\n",
        "init_lr = 0.0003\n",
        "optimizer = torch.optim.AdamW(net.parameters(), lr=init_lr)\n",
        "scheduler_warmup = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: min((t+1)/num_warmup, 1.0) ) # warmup scheduler\n",
        "scheduler_tracker = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.95, patience=1, verbose=True) # tracker scheduler\n",
        "\n",
        "# Number of mini-batches per epoch\n",
        "nb_epochs = 50\n",
        "num_warmup_batch = 0\n",
        "print('num_heads, d, num_layers, dPEt, drop, bs : ', num_heads, d, num_layers, dPEt, drop, bs)\n",
        "print('beta_1, beta_T, num_t :', beta_1, beta_T, num_t)\n",
        "print('num_warmup, nb_epochs :',num_warmup, nb_epochs)\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(nb_epochs):\n",
        "    running_loss = 0.0\n",
        "    num_batches = 0\n",
        "    net.train()\n",
        "    sampler = MoleculeSampler(train_group, bs)\n",
        "    count = 0\n",
        "    while(not sampler.is_empty()):\n",
        "        sz = sampler.choose_molecule_size()\n",
        "        indices = sampler.draw_batch_of_molecules(sz)\n",
        "        batch_x0 = torch.stack( [ train_group[sz][i].atom_type for i in indices] ).long().to(device) # [bs, n]\n",
        "        batch_e0 = torch.stack( [ train_group[sz][i].bond_type for i in indices] ).long().to(device) # [bs, n, n]\n",
        "        batch_sample_t = torch.randint(0, num_t, (batch_x0.size(0),)).long().to(device) # random interger in {0,1,...,T-1} [bs]\n",
        "        bs2, n = batch_x0.size()\n",
        "        batch_noise_x_t = torch.randn(bs2,n,num_atom_type).to(device) # [bs, n, num_atom_type]\n",
        "        batch_noise_e_t = torch.randn(bs2,n,n,num_bond_type).to(device) # [bs, n, n, num_bond_type]\n",
        "        batch_noise_e_t = sym_tensor(batch_noise_e_t)\n",
        "        x_t, e_t = net.forward_process(batch_x0, batch_e0, batch_sample_t, batch_noise_x_t, batch_noise_e_t) # [bs, n], [bs, n, n]\n",
        "        noise_pred_x_t, noise_pred_e_t = net.backward_process(x_t, e_t, batch_sample_t) # [bs, n], [bs, n, n]\n",
        "        loss_DDPM = torch.nn.MSELoss()(noise_pred_x_t, batch_noise_x_t) + 1.0* torch.nn.MSELoss()(noise_pred_e_t, batch_noise_e_t)\n",
        "        loss = loss_DDPM\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(net.parameters(), 0.25) # grad_norm_clip=1.0\n",
        "        optimizer.step()\n",
        "        if num_warmup_batch < num_warmup:\n",
        "            scheduler_warmup.step() # warmup scheduler\n",
        "        num_warmup_batch += 1\n",
        "        # Compute stats\n",
        "        running_loss += loss.detach().item()\n",
        "        num_batches += 1\n",
        "    # Average stats\n",
        "    mean_loss = running_loss/ num_batches\n",
        "    if num_warmup_batch >= num_warmup:\n",
        "        scheduler_tracker.step(mean_loss) # tracker scheduler defined w.r.t. loss value\n",
        "    elapsed = (time.time()-start)/60\n",
        "    print('epoch= %d \\t time= %.4f min \\t lr= %.7f \\t loss= %.4f' % (epoch, elapsed, optimizer.param_groups[0]['lr'], mean_loss) )\n",
        "    # Check lr value\n",
        "    if optimizer.param_groups[0]['lr'] < 10**-6:\n",
        "      print(\"\\n lr is equal to min lr -- training stopped\\n\")\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es3dyMaVUq_S"
      },
      "source": [
        "### Validity of Generated Molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oXqikewUq_T",
        "outputId": "1162c449-03e3-41f5-ada4-c03e8cc1bc71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_atom_sampled : 25\n",
            "num_atom_sampled : 19\n",
            "num_atom_sampled : 28\n",
            "num_atom_sampled : 25\n",
            "num_atom_sampled : 20\n",
            "num_atom_sampled : 24\n",
            "num_atom_sampled : 20\n",
            "num_atom_sampled : 21\n",
            "num_atom_sampled : 11\n",
            "num_atom_sampled : 23\n",
            "percentage of valid molecules\n",
            "num_gen_mol= 1000   time(min)= 2.616   perc valid molecules= 12.8\n"
          ]
        }
      ],
      "source": [
        "# compute percentage of valid molecules\n",
        "def compute_perc_valid_molecules(net, sampler_size, num_gen_mol=1000, num_generated_mols_per_batch=100):\n",
        "    num_batches = num_gen_mol // num_generated_mols_per_batch\n",
        "    num_valid_mol = 0\n",
        "    list_valid_mol = []\n",
        "    list_mol = []\n",
        "    start = time.time()\n",
        "    for idx in range(num_batches):\n",
        "        net.eval()\n",
        "        net.UNet.eval()\n",
        "        with torch.no_grad():\n",
        "            num_atom_sampled = sampler_size.choose_molecule_size() # sample the molecule size\n",
        "            print('num_atom_sampled :',num_atom_sampled)\n",
        "            batch_x_0, batch_e_0 = net.generate_process_ddpm(num_generated_mols_per_batch, num_atom_sampled)\n",
        "            batch_x_0 = torch.max(batch_x_0, dim=2)[1]  # [bs, n]\n",
        "            batch_e_0 = torch.max(batch_e_0, dim=3)[1] # [bs, n, n]\n",
        "            x_hat = batch_x_0.detach().to('cpu')\n",
        "            e_hat = batch_e_0.detach().to('cpu')\n",
        "            for x,e in zip(x_hat,e_hat):\n",
        "                pymol = Molecule(num_atom_sampled, num_atom_type)\n",
        "                pymol.atom_type = x\n",
        "                pymol.bond_type = e\n",
        "                smile = from_pymol_to_smile(pymol, atom_dict, bond_dict)\n",
        "                list_mol.append(smile)\n",
        "                mol = Chem.MolFromSmiles(smile)\n",
        "                if mol is not None:\n",
        "                    list_valid_mol.append(smile)\n",
        "                    num_valid_mol += 1\n",
        "    perc_valid_molecules = 100*num_valid_mol/num_gen_mol\n",
        "    line = 'num_gen_mol= ' + str(num_gen_mol) + '   time(min)= ' + str((time.time()-start)/60)[:5] + '   perc valid molecules= ' + str(perc_valid_molecules)[:6]\n",
        "    return perc_valid_molecules, list_mol, line, list_valid_mol\n",
        "\n",
        "np.random.seed(0)\n",
        "perc_valid_mol, list_mol, line, list_valid_mol = compute_perc_valid_molecules(net, sampler_size)\n",
        "del gt, net\n",
        "torch.cuda.empty_cache()\n",
        "print('percentage of valid molecules')\n",
        "print(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q18q0s-iUq_T"
      },
      "source": [
        "### Uniqueness of Generated Molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bzAY21xUq_U",
        "outputId": "6ee794b8-2d51-4991-8cf3-7f8878a20019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_generated_mol 1000\n",
            "num_unique_mol, num_mol: 1000 1000\n",
            "perc unique molecules among the generated molecules: 100.0\n"
          ]
        }
      ],
      "source": [
        "print('num_generated_mol',len(list_mol))\n",
        "num_unique_mol = 0\n",
        "for idx,mol in enumerate(list_mol):\n",
        "    list_tmp = list_mol.copy()\n",
        "    list_tmp.pop(idx)\n",
        "    if mol not in list_tmp:\n",
        "        num_unique_mol += 1\n",
        "print('num_unique_mol, num_mol:',num_unique_mol, len(list_mol))\n",
        "perc_unique_mol = 100*num_unique_mol/len(list_mol)\n",
        "print('perc unique molecules among the generated molecules:', str(perc_unique_mol)[:6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ybEWEczUt2T"
      },
      "source": [
        "## Performance Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoRPCRfyUt2T"
      },
      "source": [
        "Training was conducted over 50 epochs on a small subset of the ZINC dataset (2,000 training samples and 200 testing samples) with a fixed random seed. The results presented are the mean loss (and standard deviation) from the last 10 epochs, the percentage of valid molecules, the percentage of unique molecules, and the time taken to train the model.\n",
        "\n",
        "|     Network      | Train Loss on ZINC | Valid | Unique | Time (min) |\n",
        "| :--------------: | :---------------: | :---: | :----: | :--------: |\n",
        "|      GTv1      | 0.0680(0.0042) | 3.8% | 100.0% | 12.4043 |\n",
        "| GTv2 (Weighted) | 0.0622(0.0023) | **14.5%** | 100.0% | 21.6791 |\n",
        "|  GTv2 (Gated)  | 0.0595(0.0022) | 10.4% | 100.0% | 23.2297 |\n",
        "|  GTv2 (Mixed)  | 0.0623(0.0023) | 13.3% | 100.0% | 22.8696 |\n",
        "|   GTv2 (FiLM)   | **0.0575**(0.0033) | 12.8% | 100.0 | 22.9364 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFBd8sP5Ut2T"
      },
      "source": [
        "## References\n",
        "\n",
        "1. [Vijay Prakash Dwivedi and Xavier Bresson. \"A generalization of transformer networks to graphs.\" *arXiv preprint arXiv:2012.09699* (2020).](https://arxiv.org/abs/2012.09699)\n",
        "\n",
        "2. [Jonathan Ho, Ajay Jain and Pieter Abbeel. \"Denoising diffusion probabilistic models.\" Advances in neural information processing systems 33 (2020): 6840-6851.](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html)\n",
        "\n",
        "3. [Ethan Perez, Florian Strub, Harm de Vries, Vincent Dumoulin and Aaron Courville. \"Film: Visual reasoning with a general conditioning layer.\" In Proceedings of the AAAI conference on artificial intelligence, vol. 32, no. 1. 2018.](https://ojs.aaai.org/index.php/AAAI/article/view/11671)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v6bfywqcUt2T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gtv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
